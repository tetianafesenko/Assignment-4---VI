{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual Questions [25 pts]: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. [4 pts] In your own words, what is a feed-forward neural network (FFNN)? Provide a graphical illustration for a feed-forward neural network with input, hidden and output layers. Supporting your answer with mathematical expressions is certainly encouraged. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: A feed-forward neural network is a type of network that takes input data and processes it through multiple cross-connected layers and produces an output or a prediction.\n",
    "Below is a graphical representation of FFNN with input, hidden and output layers:\n",
    "\n",
    "Mathematically, it can be expressed as: z = w * x + b\n",
    " - Each neuron in the input layer receives an input value denoted as \"x\", which could be a set of numbers.\n",
    " - This input value \"x\" is multiplied by a weight \"w\" and added to a bias \"b\"\n",
    " - The result of this multiplication and addition is the weighted sum\"z\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. [4 pts] In your own words, what is a convolutional neural network (CNN)? What is the difference compared to a feed-forward neural network? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN (convolutional neural network) is a type of neural network designed to process grid-like data. Ex: images. It uses special layers called convolutional layers to automatically learn patterns or features from the data. \n",
    "\n",
    "The main differences between CNN and FFNN are that CNN have convolutional layers for capturing local patterns, using local connectivity and parameter sharing for efficient learning, and often incorporate pooling layers for downsampling. Overall, CNNs are specialized more for image-like data processing.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. [4 pts] Explain the principle of minimizing a cost function ùê∂ using gradient descent. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is a backbone of ML. It‚Äôs a method that is used to minimize a cost function in machine learning by taking small steps in the direction of the steepest decrease in the cost function until the best model parameters are found. \n",
    "\n",
    "It is like finding the quickest way downhill. It adjusts the model's parameters in small steps based on the slope of the cost function C. By constantly moving in the direction of steepest decrease, it helps the model find the best parameters that minimize the cost function C and improve its predictions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. [5 pts] In your opinion, why is it useful to use non-linear activation functions in a neural network? Conceptual or technical answers are both accepted. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear activation functions are useful in neural networks because they allow the model to learn complex patterns, capture diverse representations, and approximate any arbitrary function, making it more powerful, flexible, and capable of generalization.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. [5 pts] In a multi-classification problem with ùêæ classes, a neural network has an output layer with size ùêæ > 2. Explain why having a size ùêæ instead of a size 1 at the output layer is useful for multi-classification. Second, explain why using ‚ÄòSoftmax‚Äô activation is better compared to ‚ÄòSigmoid‚Äô activation at the output layer with size ùêæ. \n",
    " - Hint for first question: Consider the case of ùêæ = 3 classes, when the prediction we want to express is 50% to get class 0 and 50% chance to get class 2. \n",
    " - Remark: In this context a linear activation function means the identity function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a size K (greater than 1) at the output layer is better and allows the model to produce probabilities for K classes, making it easier to interpret and analyze. \n",
    "\n",
    "'Softmax' activation is better than 'Sigmoid' activation at the output layer because it produces valid probability distributions and captures class relationships, leading to more accurate predictions, while 'Sigmoid' may suffer from issues like ambiguous predictions and lack of class dependencies.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. [3 pts] Think of all the models and algorithms you‚Äôve learned so far. Specifically, k-Nearest Neighbors (k-NN), Decision Trees and Linear Regression. What are some of the advantages and disadvantages of Neural Network models compared to those? What types of problems might Neural Networks be better or worse suited to than these algorithms (e.g. problems with more or less data, supervised vs unsupervised learning, etc.)? \n",
    "\n",
    " - Remark: This is a more open-ended question. We just want to see how you think- you don‚Äôt need to compare/contrast neural networks to each of those three models in detail, no need to cover all bases. Feel free to just pick one of the models you have seen (e.g. Decision Trees, although you are welcome to do more). Keep your answers as short as you can. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks vs. XGBoost:\n",
    "\n",
    "##### Advantages of Neural Networks:\n",
    "\n",
    " - Learn complex patterns from large data\n",
    " - Handle high-dimensional data and nonlinear relationships\n",
    " - Can be used for supervised and unsupervised learning\n",
    " - Adapt and generalize well to new data\n",
    "\n",
    "\n",
    "##### Disadvantages of Neural Networks:\n",
    "\n",
    " - Computationally expensive\n",
    " - May require large amounts of data\n",
    " - Lack interpretability\n",
    " - Prone to overfitting\n",
    "\n",
    "##### Neural Networks are better for:\n",
    "\n",
    "        Large datasets, complex patterns, adaptability\n",
    "\n",
    "##### XGBoost is better for:\n",
    "\n",
    "        Smaller datasets, simple patterns, interpretability, faster training and inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
